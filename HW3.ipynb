{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRJNDGiPU37"
      },
      "source": [
        "## TECHIN 513 - Basic ML\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Install the required packages (scikit-learn, TensorFlow, Keras, PyTorch, and, pandas) if they are not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /Users/jieji/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
            "Requirement already satisfied: TensorFlow in /Users/jieji/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
            "Requirement already satisfied: Keras in /Users/jieji/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
            "Collecting PyTorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pandas in /Users/jieji/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /Users/jieji/anaconda3/lib/python3.11/site-packages (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (4.25.1)\n",
            "Requirement already satisfied: setuptools in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (68.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from TensorFlow) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->TensorFlow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->TensorFlow) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->TensorFlow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->TensorFlow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->TensorFlow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->TensorFlow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->TensorFlow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->TensorFlow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->TensorFlow) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->TensorFlow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->TensorFlow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->TensorFlow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jieji/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->TensorFlow) (3.2.2)\n",
            "Building wheels for collected packages: PyTorch\n",
            "  Building wheel for PyTorch (setup.py) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/qg/fgc5kv4d6g580zcr6yc6z7hw0000gn/T/pip-install-wb93f0ve/pytorch_0ecb0a6cf69c4c9083568807ddf2c03a/setup.py\", line 15, in <module>\n",
            "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
            "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[31m  ERROR: Failed building wheel for PyTorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for PyTorch\n",
            "Failed to build PyTorch\n",
            "\u001b[31mERROR: Could not build wheels for PyTorch, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-14 06:00:15.788364: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# use pip to install the packages\n",
        "!pip install scikit-learn TensorFlow Keras PyTorch pandas numpy\n",
        "\n",
        "# Import necessary packages\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import RandomForestClassifier from sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 1: Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 2: Split the data into training and testing sets\n",
        "# use train_test_split function to split the data with test_size = 0.2 and random_state = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Task 3: Train a Random Forest Classifier on the training data\n",
        "# import RandomForestClassifier from sklearn and fit it with training data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the model\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Fit the model with training data\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the classifier: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Task 4: Evaluate the classifier on the testing data\n",
        "# use clf.score function to evaluate the classifier on the testing data\n",
        "# print the accuracy of the classifier\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy of the classifier: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 5: Load the MNIST dataset\n",
        "# use keras.datasets.mnist.load_data() to load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 6: Preprocess the data\n",
        "# Normalize the images\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2660 - accuracy: 0.9248\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1066 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9795\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9895\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x17cac0390>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Task 7: Define and train a simple neural network using Keras\n",
        "# use Sequential model from keras.models\n",
        "# use Dense layer from keras.layers\n",
        "# use 'adam' as optimizer and 'categorical_crossentropy' as loss function\n",
        "# use model.fit to train the model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(28 * 28,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0714 - accuracy: 0.9774\n",
            "Test Accuracy: 0.977400004863739\n"
          ]
        }
      ],
      "source": [
        "# Task 8: Evaluate the neural network on the testing data\n",
        "# use model.evaluate to get the test loss and test accuracy\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task 9: Define a simple linear regression model using PyTorch\n",
        "# create a class LinearRegression that inherit from nn.Module\n",
        "# define the constructor and forward function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # Define the single layer of the linear model, with 1 input feature and 1 output feature.\n",
        "        self.linear = nn.Linear(1, 1)  # Parameters: in_features, out_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass through the layer.\n",
        "        return self.linear(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 9.8076\n",
            "Epoch [200/1000], Loss: 7.8144\n",
            "Epoch [300/1000], Loss: 6.4663\n",
            "Epoch [400/1000], Loss: 5.5545\n",
            "Epoch [500/1000], Loss: 4.9378\n",
            "Epoch [600/1000], Loss: 4.5207\n",
            "Epoch [700/1000], Loss: 4.2385\n",
            "Epoch [800/1000], Loss: 4.0477\n",
            "Epoch [900/1000], Loss: 3.9186\n",
            "Epoch [1000/1000], Loss: 3.8313\n",
            "Learned weight: 1.998740315437317\n",
            "Learned bias: 2.2914462089538574\n"
          ]
        }
      ],
      "source": [
        "# Task 10: Train the linear regression model on some dummy data and print the weight and bias\n",
        "# create an instance of LinearRegression\n",
        "# use nn.MSELoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias\n",
        "# Generate some dummy data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Assuming LinearRegression is already defined as per the previous instructions\n",
        "\n",
        "# Create an instance of the LinearRegression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define the loss function (Mean Squared Error Loss)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer (Stochastic Gradient Descent)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)  # Learning rate\n",
        "\n",
        "# Generate some dummy data\n",
        "# Let's say we want to model a simple relationship: y = 2x + 3, plus some noise\n",
        "x_train = torch.randn(100, 1) * 10  # 100 data points\n",
        "y_train = 2*x_train + 3 + torch.randn(100, 1) * 2  # Add some noise for realism\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000  # Number of iterations\n",
        "for epoch in range(num_epochs):\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_train)\n",
        "    \n",
        "    # Compute loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    \n",
        "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the weights\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Print statistics\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Print the learned weight and bias\n",
        "print(f'Learned weight: {model.linear.weight.item()}')\n",
        "print(f'Learned bias: {model.linear.bias.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIaALYXVy1J"
      },
      "source": [
        "# Bonus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-ZYu5X7gV1L9"
      },
      "outputs": [],
      "source": [
        "# Bonus Task: Implement a Convolutional Neural Network to classify the CIFAR-10 dataset\n",
        "# use torchvision.datasets.CIFAR10 to load the dataset\n",
        "# create a class CNN that inherit from nn.Module\n",
        "# define the constructor, forward function and the network architecture\n",
        "# use CrossEntropyLoss as criterion, optim.SGD as optimizer\n",
        "# use model.parameters() as input for optimizer\n",
        "# use optimizer.step() and criterion to update the model weight and bias\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.874\n",
            "[1,  4000] loss: 1.510\n",
            "[1,  6000] loss: 1.378\n",
            "[1,  8000] loss: 1.297\n",
            "[1, 10000] loss: 1.190\n",
            "[1, 12000] loss: 1.101\n",
            "[2,  2000] loss: 0.981\n",
            "[2,  4000] loss: 0.969\n",
            "[2,  6000] loss: 0.893\n",
            "[2,  8000] loss: 0.906\n",
            "[2, 10000] loss: 0.876\n",
            "[2, 12000] loss: 0.849\n",
            "[3,  2000] loss: 0.691\n",
            "[3,  4000] loss: 0.688\n",
            "[3,  6000] loss: 0.703\n",
            "[3,  8000] loss: 0.696\n",
            "[3, 10000] loss: 0.681\n",
            "[3, 12000] loss: 0.678\n",
            "[4,  2000] loss: 0.463\n",
            "[4,  4000] loss: 0.488\n",
            "[4,  6000] loss: 0.479\n",
            "[4,  8000] loss: 0.507\n",
            "[4, 10000] loss: 0.500\n",
            "[4, 12000] loss: 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(56219) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(56225) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5,  2000] loss: 0.274\n",
            "[5,  4000] loss: 0.290\n",
            "[5,  6000] loss: 0.292\n",
            "[5,  8000] loss: 0.315\n",
            "[5, 10000] loss: 0.344\n",
            "[5, 12000] loss: 0.336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(56749) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(56757) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6,  2000] loss: 0.144\n",
            "[6,  4000] loss: 0.155\n",
            "[6,  6000] loss: 0.174\n",
            "[6,  8000] loss: 0.196\n",
            "[6, 10000] loss: 0.185\n",
            "[6, 12000] loss: 0.218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(57271) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(57278) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7,  2000] loss: 0.082\n",
            "[7,  4000] loss: 0.085\n",
            "[7,  6000] loss: 0.097\n",
            "[7,  8000] loss: 0.117\n",
            "[7, 10000] loss: 0.141\n",
            "[7, 12000] loss: 0.149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(57794) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(57803) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8,  2000] loss: 0.065\n",
            "[8,  4000] loss: 0.054\n",
            "[8,  6000] loss: 0.072\n",
            "[8,  8000] loss: 0.082\n",
            "[8, 10000] loss: 0.094\n",
            "[8, 12000] loss: 0.109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(58296) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(58302) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9,  2000] loss: 0.057\n",
            "[9,  4000] loss: 0.054\n",
            "[9,  6000] loss: 0.070\n",
            "[9,  8000] loss: 0.077\n",
            "[9, 10000] loss: 0.075\n",
            "[9, 12000] loss: 0.064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python(58791) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(58793) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10,  2000] loss: 0.048\n",
            "[10,  4000] loss: 0.038\n",
            "[10,  6000] loss: 0.061\n",
            "[10,  8000] loss: 0.051\n",
            "[10, 10000] loss: 0.055\n",
            "[10, 12000] loss: 0.069\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
